{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlsxwriter in /Users/poojap/opt/anaconda3/envs/dataenv/lib/python3.11/site-packages (3.1.9)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from scipy import stats\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "!pip install xlsxwriter\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/poojap/Documents/SoderlingLab/MEA_analysis/analysis\n"
     ]
    }
   ],
   "source": [
    "currdir = os.getcwd()\n",
    "parent = os.path.dirname(currdir)\n",
    "gparent = os.path.dirname(parent)\n",
    "print(currdir)\n",
    "lines_to_skip = 10 # adjust this as necessary\n",
    "\n",
    "# count the number of header lines\n",
    "header_lines = 3 # adjust this as necessary\n",
    "\n",
    "plate_type = 'DIV12'\n",
    "subfolder = 'LSL-Cas9-PVcre_5thbatch'\n",
    "# read the csv file into a pandas DataFrame, skipping the metadata at the top\n",
    "# df = pd.read_csv(filename, skiprows=lines_to_skip, header=[i for i in range(header_lines)])\n",
    "### read all data\n",
    "dose1_folder = f\"{parent}/data/DIV19_CNO/Div19_5uM_CNO\"\n",
    "\n",
    "exp1 = pd.read_csv(f'{parent}/data/{plate_type}/{subfolder}/DIV 12 LSL-Cas9-PVcre with fith batch of gRNAs plate1(000)(000)_CompiledData.csv',\n",
    "                   engine='python', skiprows = lines_to_skip)\n",
    "exp2 = pd.read_csv(f'{parent}/data/{plate_type}/{subfolder}/DIV 12 LSL-Cas9-PVcre with fith batch of gRNAs plate2(000)(000)_CompiledData.csv',\n",
    "                   engine='python', skiprows = lines_to_skip)\n",
    "exp3 = pd.read_csv(f'{parent}/data/{plate_type}/{subfolder}/DIV 12 LSL-Cas9-PVcre with fith batch of gRNAs plate1(000)(000)_CompiledData.csv',\n",
    "                   engine='python',\n",
    "                  skiprows = lines_to_skip)\n",
    "\n",
    "exp1 = exp1.drop(columns=['Unnamed: 9'])\n",
    "exp2 = exp2.drop(columns=['Unnamed: 9'])\n",
    "exp3 = exp3.drop(columns=['Unnamed: 9'])\n",
    "\n",
    "##\n",
    "\n",
    "firstTableHeading = \"Mean Firing Rate (Hz)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0  GPR37L 1  GPR37L 2  LGI2 A12   SLITRK5   THSD7 1   THSD7 2  \\\n",
      "260        NaN  8.000000  8.000000  8.000000  8.000000  8.000000  8.000000   \n",
      "261        NaN  8.000000  8.000000  8.000000  8.000000  8.000000  8.000000   \n",
      "262        NaN  8.000000  8.000000  8.000000  8.000000  8.000000  8.000000   \n",
      "263        NaN  8.000000  8.000000  8.000000  8.000000  8.000000  8.000000   \n",
      "264        NaN  8.000000  8.000000  8.000000  7.000000  7.000000  8.000000   \n",
      "265        NaN  8.000000  8.000000  8.000000  8.000000  8.000000  8.000000   \n",
      "266        NaN  8.000000  8.000000  8.000000  8.000000  8.000000  8.000000   \n",
      "267        NaN  8.000000  8.000000  8.000000  8.000000  8.000000  8.000000   \n",
      "268        NaN  8.000000  8.000000  8.000000  8.000000  8.000000  8.000000   \n",
      "269        NaN  7.000000  8.000000  7.000000  8.000000  8.000000  8.000000   \n",
      "\n",
      "         unt1      unt2  \n",
      "260  8.000000  8.000000  \n",
      "261  8.000000  8.000000  \n",
      "262  8.000000  8.000000  \n",
      "263  8.000000  8.000000  \n",
      "264  8.000000  8.000000  \n",
      "265  8.000000  8.000000  \n",
      "266  8.000000  8.000000  \n",
      "267  8.000000  8.000000  \n",
      "268  8.000000  8.000000  \n",
      "269  8.000000  8.000000  \n"
     ]
    }
   ],
   "source": [
    "print(exp1.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rename_row_names(experiment_df):\n",
    "    replace_rows = experiment_df['Unnamed: 0'].isin(['B Replicates', np.nan]) \n",
    "    replace_count = replace_rows.sum()\n",
    "    \n",
    "    replicates = (f\"B Replicate {i+1}\" for i in range(replace_count))\n",
    "    with pd.option_context('mode.chained_assignment', None):\n",
    "        experiment_df.loc[replace_rows, 'Unnamed: 0'] = list(replicates)\n",
    "    return experiment_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Mean Firing Rate (Hz)', 'Number of Active Electrodes', 'Weighted Mean Firing Rate (Hz)', 'Number of Bursting Electrodes', 'Burst Frequency - Avg (Hz)', 'Burst Duration - Avg (s)', 'Normalized Duration IQR - Avg', 'IBI Coefficient of Variation - Avg', 'Burst Percentage - Avg', 'Network Burst Frequency (Hz)', 'Network Burst Duration - Avg (sec)', 'Network Burst Percentage', 'Network IBI Coefficient of Variation', 'Network Normalized Duration IQR', 'Area Under Normalized Cross-Correlation', 'Resistance - Avg (kOhms)', 'Number of Covered Electrodes'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def section_data(exp_num, firstHeading):\n",
    "    maxrows = exp_num.shape[0]\n",
    "    vals_between_tables = 16\n",
    "    titles = [heading_ind for heading_ind in range(14, maxrows+16, 16)]\n",
    "    # print(titles[-1], print(exp_num.iloc[254]))\n",
    "    # print(maxrows, titles)\n",
    "    # print(maxrows, titles)\n",
    "    titles.insert(0,0)\n",
    "\n",
    "    # # Empty dictionary to store dataframes\n",
    "    experiment = {}\n",
    "    \n",
    "    # Loop through start indices\n",
    "    for ind in range(len(titles) -1):\n",
    "\n",
    "        if ind == 0:\n",
    "            ## Handle mean firing rate\n",
    "            key = firstHeading\n",
    "            table = exp_num.iloc[titles[ind] : titles[ind +1], :]\n",
    "            table = rename_row_names(table)\n",
    "        elif ind != 0:\n",
    "            table = exp_num.iloc[titles[ind] : titles[ind +1], :]\n",
    "\n",
    "            key = table.iloc[0][0]\n",
    "            table = exp_num.iloc[titles[ind] +2: titles[ind +1], :]\n",
    "\n",
    "            table = rename_row_names(table)\n",
    "        table.set_index('Unnamed: 0', inplace=True)\n",
    "        experiment[key] = table\n",
    "    return experiment                   \n",
    "exp1_dict = section_data(exp1, firstTableHeading)\n",
    "exp2_dict = section_data(exp2, firstTableHeading)\n",
    "exp3_dict = section_data(exp3, firstTableHeading)\n",
    "exp3_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [exp1_dict, exp2_dict, exp3_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_is_in(sub_df, df):\n",
    "    # Convert rows of each DataFrame to tuples\n",
    "    sub_tuples = set(sub_df.apply(tuple, axis=1))\n",
    "    df_tuples = set(df.apply(tuple, axis=1))\n",
    "    \n",
    "    # Check if all tuples of sub_df exist in df\n",
    "    return sub_tuples.issubset(df_tuples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merge_experiments_DIV(list_of_dicts):\n",
    "    data = {}\n",
    "    for i, dictionary in enumerate(list_of_dicts):\n",
    "        data[f\"exp{i +1}\"] = dictionary\n",
    "    merged_data = data[\"exp1\"].copy()\n",
    "    \n",
    "    for i, (exp, dictionary) in enumerate(data.items()):\n",
    "        if exp == \"exp1\":\n",
    "            continue\n",
    "        for key, value in dictionary.items():\n",
    "            merged_data[key] = pd.concat([merged_data[key], value])\n",
    "\n",
    "\n",
    "    return merged_data\n",
    "\n",
    "data = merge_experiments_DIV(experiments)\n",
    "len(list(data.keys()))\n",
    "data['Mean Firing Rate (Hz)'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Mean Firing Rate (Hz)', 'Number of Active Electrodes', 'Weighted Mean Firing Rate (Hz)', 'Number of Bursting Electrodes', 'Burst Frequency - Avg (Hz)', 'Burst Duration - Avg (s)', 'Normalized Duration IQR - Avg', 'IBI Coefficient of Variation - Avg', 'Burst Percentage - Avg', 'Network Burst Frequency (Hz)', 'Network Burst Duration - Avg (sec)', 'Network Burst Percentage', 'Network IBI Coefficient of Variation', 'Network Normalized Duration IQR', 'Area Under Normalized Cross-Correlation', 'Resistance - Avg (kOhms)', 'Number of Covered Electrodes'])\n",
      "(42, 8)\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())\n",
    "print(data['Mean Firing Rate (Hz)'].shape)\n",
    "\n",
    "# data['exp2']['Mean Firing Rate (Hz)'].shape\n",
    "\n",
    "# data['Mean Firing Rate (Hz)'].to_csv(\"data_exp1_meanfiringrate_check.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reindex on an axis with duplicate labels",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[39mreturn\u001b[39;00m dictionary\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m key, dictionary \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mitems():\n\u001b[0;32m----> 8\u001b[0m     data \u001b[39m=\u001b[39m remove_mean_SEM(dictionary)\n",
      "Cell \u001b[0;32mIn[25], line 4\u001b[0m, in \u001b[0;36mremove_mean_SEM\u001b[0;34m(dictionary)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m key, table \u001b[39min\u001b[39;00m dictionary\u001b[39m.\u001b[39mitems():\n\u001b[1;32m      3\u001b[0m     table\u001b[39m.\u001b[39mdrop([\u001b[39m'\u001b[39m\u001b[39mB Mean\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mB SEM\u001b[39m\u001b[39m'\u001b[39m], axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m     dictionary[key] \u001b[39m=\u001b[39m table\n\u001b[1;32m      5\u001b[0m \u001b[39mreturn\u001b[39;00m dictionary\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataenv/lib/python3.11/site-packages/pandas/core/frame.py:3950\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3947\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3948\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3949\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> 3950\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_item(key, value)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataenv/lib/python3.11/site-packages/pandas/core/frame.py:4143\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4134\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4135\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4136\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4141\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4142\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4143\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sanitize_column(value)\n\u001b[1;32m   4145\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   4146\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m   4147\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   4148\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4149\u001b[0m     ):\n\u001b[1;32m   4150\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4151\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataenv/lib/python3.11/site-packages/pandas/core/frame.py:4867\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4865\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[1;32m   4866\u001b[0m \u001b[39melif\u001b[39;00m is_dict_like(value):\n\u001b[0;32m-> 4867\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[1;32m   4869\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m   4870\u001b[0m     com\u001b[39m.\u001b[39mrequire_length_match(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataenv/lib/python3.11/site-packages/pandas/core/frame.py:11615\u001b[0m, in \u001b[0;36m_reindex_for_setitem\u001b[0;34m(value, index)\u001b[0m\n\u001b[1;32m  11611\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m  11612\u001b[0m     \u001b[39m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[39;00m\n\u001b[1;32m  11613\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m value\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mis_unique:\n\u001b[1;32m  11614\u001b[0m         \u001b[39m# duplicate axis\u001b[39;00m\n\u001b[0;32m> 11615\u001b[0m         \u001b[39mraise\u001b[39;00m err\n\u001b[1;32m  11617\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m  11618\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mincompatible index of inserted column with frame index\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m  11619\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m  11620\u001b[0m \u001b[39mreturn\u001b[39;00m reindexed_value\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataenv/lib/python3.11/site-packages/pandas/core/frame.py:11610\u001b[0m, in \u001b[0;36m_reindex_for_setitem\u001b[0;34m(value, index)\u001b[0m\n\u001b[1;32m  11608\u001b[0m \u001b[39m# GH#4107\u001b[39;00m\n\u001b[1;32m  11609\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m> 11610\u001b[0m     reindexed_value \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mreindex(index)\u001b[39m.\u001b[39m_values\n\u001b[1;32m  11611\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m  11612\u001b[0m     \u001b[39m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[39;00m\n\u001b[1;32m  11613\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m value\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mis_unique:\n\u001b[1;32m  11614\u001b[0m         \u001b[39m# duplicate axis\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataenv/lib/python3.11/site-packages/pandas/core/series.py:4918\u001b[0m, in \u001b[0;36mSeries.reindex\u001b[0;34m(self, index, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[1;32m   4901\u001b[0m \u001b[39m@doc\u001b[39m(\n\u001b[1;32m   4902\u001b[0m     NDFrame\u001b[39m.\u001b[39mreindex,  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m   4903\u001b[0m     klass\u001b[39m=\u001b[39m_shared_doc_kwargs[\u001b[39m\"\u001b[39m\u001b[39mklass\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4916\u001b[0m     tolerance\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   4917\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series:\n\u001b[0;32m-> 4918\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mreindex(\n\u001b[1;32m   4919\u001b[0m         index\u001b[39m=\u001b[39mindex,\n\u001b[1;32m   4920\u001b[0m         method\u001b[39m=\u001b[39mmethod,\n\u001b[1;32m   4921\u001b[0m         copy\u001b[39m=\u001b[39mcopy,\n\u001b[1;32m   4922\u001b[0m         level\u001b[39m=\u001b[39mlevel,\n\u001b[1;32m   4923\u001b[0m         fill_value\u001b[39m=\u001b[39mfill_value,\n\u001b[1;32m   4924\u001b[0m         limit\u001b[39m=\u001b[39mlimit,\n\u001b[1;32m   4925\u001b[0m         tolerance\u001b[39m=\u001b[39mtolerance,\n\u001b[1;32m   4926\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataenv/lib/python3.11/site-packages/pandas/core/generic.py:5360\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[0;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[1;32m   5357\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_multi(axes, copy, fill_value)\n\u001b[1;32m   5359\u001b[0m \u001b[39m# perform the reindex on the axes\u001b[39;00m\n\u001b[0;32m-> 5360\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_axes(\n\u001b[1;32m   5361\u001b[0m     axes, level, limit, tolerance, method, fill_value, copy\n\u001b[1;32m   5362\u001b[0m )\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreindex\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataenv/lib/python3.11/site-packages/pandas/core/generic.py:5375\u001b[0m, in \u001b[0;36mNDFrame._reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   5372\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m   5374\u001b[0m ax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis(a)\n\u001b[0;32m-> 5375\u001b[0m new_index, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39mreindex(\n\u001b[1;32m   5376\u001b[0m     labels, level\u001b[39m=\u001b[39mlevel, limit\u001b[39m=\u001b[39mlimit, tolerance\u001b[39m=\u001b[39mtolerance, method\u001b[39m=\u001b[39mmethod\n\u001b[1;32m   5377\u001b[0m )\n\u001b[1;32m   5379\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(a)\n\u001b[1;32m   5380\u001b[0m obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   5381\u001b[0m     {axis: [new_index, indexer]},\n\u001b[1;32m   5382\u001b[0m     fill_value\u001b[39m=\u001b[39mfill_value,\n\u001b[1;32m   5383\u001b[0m     copy\u001b[39m=\u001b[39mcopy,\n\u001b[1;32m   5384\u001b[0m     allow_dups\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   5385\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataenv/lib/python3.11/site-packages/pandas/core/indexes/base.py:4275\u001b[0m, in \u001b[0;36mIndex.reindex\u001b[0;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[1;32m   4272\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot handle a non-unique multi-index!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   4273\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_unique:\n\u001b[1;32m   4274\u001b[0m     \u001b[39m# GH#42568\u001b[39;00m\n\u001b[0;32m-> 4275\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   4276\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   4277\u001b[0m     indexer, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_indexer_non_unique(target)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex on an axis with duplicate labels"
     ]
    }
   ],
   "source": [
    "def remove_mean_SEM(dictionary):\n",
    "    for key, table in dictionary.items():\n",
    "        table.drop(['B Mean', 'B SEM'], axis = 0, inplace=True)\n",
    "        dictionary[key] = table\n",
    "    return dictionary\n",
    "\n",
    "for key, dictionary in data.items():\n",
    "    data = remove_mean_SEM(dictionary)\n",
    "# print(basal_dict['Number of Covered Electrodes'].columns)\n",
    "# dose1_dictmessy['Mean Firing Rate (Hz)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mean Firing Rate (Hz)': {'GPR37L 1': [-3.512461934976752,\n",
       "   0.0007820620538489373],\n",
       "  'GPR37L 2': [2.882072139616893, 0.005242025933865089],\n",
       "  'LGI2 A12': [-4.471781454337339, 2.9234062784044448e-05],\n",
       "  'SLITRK5': [-0.9230712109710678, 0.3591409683703768],\n",
       "  'THSD7 1': [-7.092952178728836, 8.45292200803454e-10],\n",
       "  'THSD7 2': [-5.622808074352924, 3.578077329196222e-07]},\n",
       " 'Number of Active Electrodes': {'GPR37L 1': [-1.4348601079588734,\n",
       "   0.1557799085449525,\n",
       "   'Warning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.'],\n",
       "  'GPR37L 2': [nan,\n",
       "   nan,\n",
       "   'Warning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.'],\n",
       "  'LGI2 A12': [-0.9999999999999967,\n",
       "   0.32075485777547497,\n",
       "   'Warning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.'],\n",
       "  'SLITRK5': [-1.6161498378886354,\n",
       "   0.11056029908555128,\n",
       "   'Warning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.'],\n",
       "  'THSD7 1': [-1.4348601079588734,\n",
       "   0.1557799085449525,\n",
       "   'Warning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.'],\n",
       "  'THSD7 2': [-0.9999999999999967,\n",
       "   0.32075485777547497,\n",
       "   'Warning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.']},\n",
       " 'Weighted Mean Firing Rate (Hz)': {'GPR37L 1': [-3.410678047628067,\n",
       "   0.0010795859679725026],\n",
       "  'GPR37L 2': [2.882072139616893, 0.005242025933865089],\n",
       "  'LGI2 A12': [-4.466412166555127, 2.9809952116446565e-05],\n",
       "  'SLITRK5': [-0.8065934329592145, 0.42263275003733813],\n",
       "  'THSD7 1': [-7.0860151289136875, 8.703046997352379e-10],\n",
       "  'THSD7 2': [-5.620746823881942, 3.607596890098526e-07]},\n",
       " 'Number of Bursting Electrodes': {'GPR37L 1': [-1.4348601079588734,\n",
       "   0.1557799085449525,\n",
       "   'Warning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.'],\n",
       "  'GPR37L 2': [nan,\n",
       "   nan,\n",
       "   'Warning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.'],\n",
       "  'LGI2 A12': [-1.7837651700316832,\n",
       "   0.0787961238746002,\n",
       "   'Warning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.'],\n",
       "  'SLITRK5': [-2.750921221621509,\n",
       "   0.007558996363794503,\n",
       "   'Warning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.'],\n",
       "  'THSD7 1': [-1.4348601079588734,\n",
       "   0.1557799085449525,\n",
       "   'Warning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.'],\n",
       "  'THSD7 2': [-0.9999999999999967,\n",
       "   0.32075485777547497,\n",
       "   'Warning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.']},\n",
       " 'Burst Frequency - Avg (Hz)': {'GPR37L 1': [-3.2972951346887527,\n",
       "   0.0015358153402600925],\n",
       "  'GPR37L 2': [1.5093296943097192, 0.1357153144843834],\n",
       "  'LGI2 A12': [-4.055803954704536, 0.0001279800827544425],\n",
       "  'SLITRK5': [0.8116398309710595, 0.4197497149581173],\n",
       "  'THSD7 1': [-7.240084000639867, 4.5503452992282384e-10],\n",
       "  'THSD7 2': [-4.942025178906169, 5.0841163963183005e-06]},\n",
       " 'Burst Duration - Avg (s)': {'GPR37L 1': [-1.1030788947274033,\n",
       "   0.27377077931528293],\n",
       "  'GPR37L 2': [2.1584848553340312, 0.03432117248497363],\n",
       "  'LGI2 A12': [-0.1684888503451042, 0.8666846072520995],\n",
       "  'SLITRK5': [-1.5364770387138935, 0.12892947267809135],\n",
       "  'THSD7 1': [-1.8156556546110458, 0.0737060524185136],\n",
       "  'THSD7 2': [-3.0655144170500503, 0.0030861723235147465]},\n",
       " 'Normalized Duration IQR - Avg': {'GPR37L 1': [1.0537669219117338,\n",
       "   0.2956134325624099],\n",
       "  'GPR37L 2': [0.2448644351114567, 0.8072777944532699],\n",
       "  'LGI2 A12': [1.8171361808316309, 0.07347657336853068],\n",
       "  'SLITRK5': [2.435637321097137, 0.017415016364432476],\n",
       "  'THSD7 1': [1.0380488475131042, 0.3028197980699231],\n",
       "  'THSD7 2': [1.848536193503915, 0.06874850946941623]},\n",
       " 'IBI Coefficient of Variation - Avg': {'GPR37L 1': [4.377124074267576,\n",
       "   4.1165064352733276e-05],\n",
       "  'GPR37L 2': [-2.7050506924260933, 0.008569327436388765],\n",
       "  'LGI2 A12': [3.6563728847771055, 0.0004911580182118227],\n",
       "  'SLITRK5': [-0.6413931541581208, 0.5233618979610983],\n",
       "  'THSD7 1': [6.969825069968301, 1.4175664352043955e-09],\n",
       "  'THSD7 2': [4.764415718669418, 9.933215360207706e-06]},\n",
       " 'Burst Percentage - Avg': {'GPR37L 1': [-0.7204632123066558,\n",
       "   0.4736389240405863],\n",
       "  'GPR37L 2': [-0.6283633117296761, 0.5318108929728169],\n",
       "  'LGI2 A12': [-0.948291505054321, 0.3462434615764718],\n",
       "  'SLITRK5': [-3.365551237683397, 0.001243237277363591],\n",
       "  'THSD7 1': [-2.0138016621550503, 0.04787561133786624],\n",
       "  'THSD7 2': [-1.153254463586909, 0.25272870414173443]},\n",
       " 'Network Burst Frequency (Hz)': {'GPR37L 1': [-3.2672736729078715,\n",
       "   0.0016840334824795367],\n",
       "  'GPR37L 2': [0.30921595467748664, 0.7580757822265356],\n",
       "  'LGI2 A12': [-3.9441551064688722, 0.00018780714305072463],\n",
       "  'SLITRK5': [nan, nan],\n",
       "  'THSD7 1': [-6.456892153908572, 1.2021242515435242e-08],\n",
       "  'THSD7 2': [-4.843624662578923, 7.377853841698854e-06]},\n",
       " 'Network Burst Duration - Avg (sec)': {'GPR37L 1': [0.02856715573973367,\n",
       "   0.9772910970340067],\n",
       "  'GPR37L 2': [2.5266240630084518, 0.013779775215606874],\n",
       "  'LGI2 A12': [1.8106902131896931, 0.07448006212965833],\n",
       "  'SLITRK5': [nan, nan],\n",
       "  'THSD7 1': [0.3387951434795845, 0.7357782564882691],\n",
       "  'THSD7 2': [-0.671610135948815, 0.504042404607044]},\n",
       " 'Network Burst Percentage': {'GPR37L 1': [-2.126026998266001,\n",
       "   0.03702976695362476],\n",
       "  'GPR37L 2': [-0.0768886362822948, 0.938931482493538],\n",
       "  'LGI2 A12': [-2.034753285072864, 0.04566484632273834],\n",
       "  'SLITRK5': [nan, nan],\n",
       "  'THSD7 1': [-3.217895387843569, 0.0019573933250047267],\n",
       "  'THSD7 2': [-3.581058526000697, 0.0006273777738446487]},\n",
       " 'Network IBI Coefficient of Variation': {'GPR37L 1': [4.557583599929697,\n",
       "   2.137240662372318e-05],\n",
       "  'GPR37L 2': [-1.9500363751426513, 0.055177556177730624],\n",
       "  'LGI2 A12': [4.1616405690516824, 8.851169156165368e-05],\n",
       "  'SLITRK5': [nan, nan],\n",
       "  'THSD7 1': [7.434292845324576, 2.0050420162148915e-10],\n",
       "  'THSD7 2': [5.549777408920191, 4.78424081992512e-07]},\n",
       " 'Network Normalized Duration IQR': {'GPR37L 1': [2.3229293130227524,\n",
       "   0.023094766179449163],\n",
       "  'GPR37L 2': [0.15214137801069158, 0.8795130909444948],\n",
       "  'LGI2 A12': [2.1857720588651, 0.03217951777620419],\n",
       "  'SLITRK5': [nan, nan],\n",
       "  'THSD7 1': [3.2212401957225905, 0.0019376351352030036],\n",
       "  'THSD7 2': [3.442181671518445, 0.0009776402606762743]},\n",
       " 'Area Under Normalized Cross-Correlation': {'GPR37L 1': [-1.8362437583890208,\n",
       "   0.07056812527737835],\n",
       "  'GPR37L 2': [-0.11619391088268897, 0.9078315685825192],\n",
       "  'LGI2 A12': [-2.1874985198063537, 0.03204803789102588],\n",
       "  'SLITRK5': [-1.267830673469713, 0.20905940313476845],\n",
       "  'THSD7 1': [-1.6482182872885178, 0.10378953836689085],\n",
       "  'THSD7 2': [-0.07804417700463694, 0.9380155728666539]},\n",
       " 'Resistance - Avg (kOhms)': {'GPR37L 1': [-0.7620634002539352,\n",
       "   0.44858229884187206],\n",
       "  'GPR37L 2': [-0.2987229745216056, 0.7660364414760388],\n",
       "  'LGI2 A12': [0.507976532101811, 0.613066814565793],\n",
       "  'SLITRK5': [-5.102914722272608, 2.7475035705808825e-06],\n",
       "  'THSD7 1': [-1.8212365121688332, 0.07284414286536907],\n",
       "  'THSD7 2': [-2.2482512457989374, 0.0277112654225463]},\n",
       " 'Number of Covered Electrodes': {'GPR37L 1': [-1.4348601079588734,\n",
       "   0.1557799085449525,\n",
       "   'Warning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.'],\n",
       "  'GPR37L 2': [nan,\n",
       "   nan,\n",
       "   'Warning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.'],\n",
       "  'LGI2 A12': [-1.4348601079588734,\n",
       "   0.1557799085449525,\n",
       "   'Warning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.'],\n",
       "  'SLITRK5': [-1.4348601079588734,\n",
       "   0.1557799085449525,\n",
       "   'Warning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.'],\n",
       "  'THSD7 1': [-1.4348601079588734,\n",
       "   0.1557799085449525,\n",
       "   'Warning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.'],\n",
       "  'THSD7 2': [-0.9999999999999967,\n",
       "   0.32075485777547497,\n",
       "   'Warning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.']}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def perform_t_test(exp_df):\n",
    "    exp_results = {}\n",
    "    for variable_test in exp_df.keys():\n",
    "        exp_results[variable_test] = {}\n",
    "        # print(exp_df[variable_test])\n",
    "        table = exp_df[variable_test].copy()  # Create a deep copy\n",
    "        table.drop(['B Mean', 'B SEM'], axis = 0, inplace=True)\n",
    "        test_variables = [col for col in table.columns if \"unt\" not in col.lower()]\n",
    "        control_name = \"unt2\"\n",
    "        for testitem in test_variables:\n",
    "            exp_group = list(table[testitem].astype(float))\n",
    "            control_group = list(table[control_name].astype(float))\n",
    "            try:\n",
    "                with warnings.catch_warnings(record=True) as w:\n",
    "                    warnings.simplefilter(\"always\")  # Cause all warnings to always be triggered\n",
    "\n",
    "                    t_stat, pval = stats.ttest_ind(exp_group, control_group)\n",
    "\n",
    "                    if len(w) > 0:\n",
    "                        # A warning occurred, add a note to the results\n",
    "                        exp_results[variable_test][testitem] = [t_stat, pval, 'Warning: ' + str(w[-1].message)]\n",
    "                    else:\n",
    "                        # No warning, add results normallytqdm\n",
    "                        ## first value is t-stat like FC, second is Pvalue\n",
    "                        exp_results[variable_test][testitem] = [t_stat, pval]\n",
    "            except RuntimeError as re:\n",
    "                # Catch any runtime errors and handle them\n",
    "                print(f'Error: {str(re)}')\n",
    "    return exp_results\n",
    "\n",
    "all_experiments_results = perform_t_test(data)\n",
    "all_experiments_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp1.iloc[62:79]\n",
    "def analyze_test_results(experiment_res, outfile):\n",
    "    col_names = ['Test Types', 'Gene', 'T-statistic', 'Regulation', 'P-value', 'Significance', 'Warnings']\n",
    "    df = pd.DataFrame(columns = col_names)\n",
    "\n",
    "    directory = os.path.dirname(outfile)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    for test in (experiment_res.keys()):\n",
    "        for prot in experiment_res[test].keys():\n",
    "            new_row = {}\n",
    "\n",
    "            new_row['Test Types'] = test\n",
    "            new_row['Gene'] = prot\n",
    "            t_stat = experiment_res[test][prot][0]\n",
    "            new_row['T-statistic'] = t_stat\n",
    "            if t_stat < 0:\n",
    "                new_row['Regulation'] = \"Down-Regulated\"\n",
    "            elif t_stat > 0:\n",
    "                new_row['Regulation'] = \"Up-Regulated\"\n",
    "            else:\n",
    "                new_row['Regulation'] = \"Same/NA\"\n",
    "            \n",
    "            pval = experiment_res[test][prot][1]\n",
    "            new_row['P-value'] = pval\n",
    "            if pval <= 0.05:\n",
    "                new_row['Significance'] = \"Significant diff between gene and control\"\n",
    "            else:\n",
    "                new_row['Significance'] = \"Not Significant\"\n",
    "            if len(experiment_res[test][prot]) > 2:\n",
    "                new_row['Warnings'] = experiment_res[test][prot][2]\n",
    "            else:\n",
    "                new_row['Warnings'] = \"No Warning\"\n",
    "\n",
    "            df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    df.to_csv(outfile)\n",
    "    return df\n",
    "\n",
    "\n",
    "test_results = analyze_test_results(all_experiments_results, f'predictions/{plate_type}/{subfolder}/all_plates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'XlsxWriter' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     21\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mProblem in experiments to excel file\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 23\u001b[0m save_all_to_excel(test_results, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpredictions/\u001b[39m\u001b[39m{\u001b[39;00mplate_type\u001b[39m}\u001b[39;00m\u001b[39m_3plates.xlsx\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 17\u001b[0m, in \u001b[0;36msave_all_to_excel\u001b[0;34m(dataframes, outfile)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m df, sheetname \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(dataframes, sheet_names):\n\u001b[1;32m     15\u001b[0m     df\u001b[39m.\u001b[39mto_excel(writer, sheet_name\u001b[39m=\u001b[39msheetname)\n\u001b[0;32m---> 17\u001b[0m writer\u001b[39m.\u001b[39msave()\n\u001b[1;32m     18\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(outfile):\n\u001b[1;32m     19\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mFile Created\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'XlsxWriter' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "\n",
    "def save_all_to_excel(dataframes, outfile):\n",
    "    # Convert single dataframe to a list of one dataframe for consistency\n",
    "    if isinstance(dataframes, pd.DataFrame):\n",
    "        dataframes = [dataframes]\n",
    "        sheet_names = ['experiment 1']\n",
    "    else:\n",
    "        sheet_names = ['experiment {}'.format(i+1) for i in range(len(dataframes))]\n",
    "\n",
    "    directory = os.path.dirname(outfile)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    writer = pd.ExcelWriter(outfile, engine='xlsxwriter')\n",
    "\n",
    "    for df, sheetname in zip(dataframes, sheet_names):\n",
    "        df.to_excel(writer, sheet_name=sheetname)\n",
    "    \n",
    "    writer.save()\n",
    "    if os.path.exists(outfile):\n",
    "        return \"File Created\"\n",
    "    else:\n",
    "        return \"Problem in experiments to excel file\"\n",
    "\n",
    "save_all_to_excel(test_results, f\"predictions/{plate_type}_3plates.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    exp1_df = section_data(exp1, firstTableHeading)\n",
    "    exp2_df = section_data(exp2, firstTableHeading)\n",
    "    exp3_df = section_data(exp3, firstTableHeading)\n",
    "    ## combine 3 tests to get analysis for all replicates \n",
    "    experiments = [exp1_dict, exp2_dict, exp3_dict]\n",
    "    data = merge_experiments_DIV(experiments)\n",
    "    all_experiments_results = perform_t_test(data)\n",
    "\n",
    "    # exp1_results = perform_t_test(exp1_df)\n",
    "    # exp2_results = perform_t_test(exp2_df)\n",
    "    # exp3_results = perform_t_test(exp3_df)\n",
    "    test_results = analyze_test_results(all_experiments_results, f'data/{plate_type}/all_plates.csv')\n",
    "    save_path = f\"predictions/{plate_type}_3plates.xlsx\"\n",
    "    save_all_to_excel(test_results, f\"predictions/{plate_type}_3plates.xlsx\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2157763/2327352467.py:17: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n",
      "  writer.save()\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    ##################################\n",
    "    ## the t-test may not be accurate because exp group and control group are very similar in 4 tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/poojaparameswaran/Documents/SoderlingLab/MEA_analysis/plots/DIV19/t_stat_DIV19',\n",
       " '/home/poojaparameswaran/Documents/SoderlingLab/MEA_analysis/plots/DIV19/regulation_count.png',\n",
       " '/home/poojaparameswaran/Documents/SoderlingLab/MEA_analysis/plots/DIV19/p_value_distribution_DIV19.png')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the plots as images\n",
    "t_statistic_path = f\"{currdir}/plots/{plate_type}/t_stat_{plate_type}\"\n",
    "regulation_path = f\"{currdir}/plots/{plate_type}/regulation_count.png\"\n",
    "p_value_path = f\"{currdir}/plots/{plate_type}/p_value_distribution_{plate_type}.png\"\n",
    "save_path = f\"predictions/{plate_type}_3plates.xlsx\"\n",
    "\n",
    "currdir = os.getcwd()\n",
    "parent = os.path.dirname(currdir)\n",
    "\n",
    "data = pd.read_excel(currdir + \"/\" +save_path )\n",
    "# Saving T-statistic vs. Test Types\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(y='Test Types', x='T-statistic', data=data, palette='coolwarm')\n",
    "plt.title('Distribution of T-statistic Values for Different Test Types')\n",
    "plt.xlabel('T-statistic')\n",
    "plt.ylabel('Test Types')\n",
    "plt.legend(title='T statistic', loc = 'lower right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(t_statistic_path)\n",
    "plt.close()\n",
    "\n",
    "# Saving Regulation Count for each Test Type\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(y='Test Types', hue='Regulation', data=data, palette='muted')\n",
    "plt.title('Number of Up-regulated vs. Down-regulated Genes per Test Type')\n",
    "plt.xlabel('Number of Genes')\n",
    "plt.ylabel('Test Types')\n",
    "plt.legend(title='Regulation', loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(regulation_path)\n",
    "plt.close()\n",
    "\n",
    "# Saving P-value Distribution for each Test Type\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(y='Test Types', x='P-value', data=data, palette='viridis', inner='quartile')\n",
    "plt.title('Distribution of P-values for Different Test Types')\n",
    "plt.xlabel('P-value')\n",
    "plt.ylabel('Test Types')\n",
    "plt.xscale('log')\n",
    "plt.legend(title='P value', loc = 'lower right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(p_value_path)\n",
    "plt.close()\n",
    "\n",
    "t_statistic_path, regulation_path, p_value_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
